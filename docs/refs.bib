
@article{moreno_stochastic_2019,
	title = {Stochastic {Modeling} {Handbook} for {Optical} {AGN} {Variability}},
	volume = {131},
	issn = {0004-6280},
	url = {https://ui.adsabs.harvard.edu/abs/2019PASP..131f3001M},
	doi = {10.1088/1538-3873/ab1597},
	abstract = {This work develops application techniques for stochastic modeling of Active Galactic Nuclei (AGNs) variability as a probe of accretion disk physics. Stochastic models, specifically Continuous Auto-Regressive Moving Average (CARMA) models, characterize light curves with a perturbation spectrum and an Impulse-Response function, which crucially provides an interpretation for variability timescales. CARMA timescales are not physical but rather, they describe correlation structure and ordered information in stochastic processes. We begin this tutorial by reviewing discrete auto-regressive and moving-average processes, we bridge these components to their continuous analogs, and lastly we investigate the significance of CARMA timescales, obtained by modeling a light curve in the time domain, in relation to the shape of the power spectrum (PSD) and structure function. We determine that higher order CARMA models, for example the Damped Harmonic Oscillator (DHO or CARMA(2, 1)) are more sensitive to deviations from a single-slope power-law description of AGN variability; unlike Damped Random Walks (DRW or CAR(1)) where the PSD slope is fixed, the DHO slope is not. Higher complexity stochastic models than the DRW capture additional covariance in data and output additional characteristic timescales that probe the driving mechanisms of variability. We provide code using Kali software to generate simulations of diverse complexity stochastic light curves. We also provide a heuristic discussion of aliasing effects in ground-based cadences and the importance of light curve length in regards to uncertainty and limitations in timescale estimation.},
	urldate = {2022-03-01},
	journal = {Publications of the Astronomical Society of the Pacific},
	author = {Moreno, Jackeline and Vogeley, Michael S. and Richards, Gordon T. and Yu, Weixiang},
	month = mar,
	year = {2019},
	note = {ADS Bibcode: 2019PASP..131f3001M},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	pages = {063001},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\4EC8WGLR\\Moreno et al. - 2019 - Stochastic Modeling Handbook for Optical AGN Varia.pdf:application/pdf},
}

@article{kelly_flexible_2014,
	title = {Flexible and {Scalable} {Methods} for {Quantifying} {Stochastic} {Variability} in the {Era} of {Massive} {Time}-domain {Astronomical} {Data} {Sets}},
	volume = {788},
	issn = {0004-637X},
	url = {https://ui.adsabs.harvard.edu/abs/2014ApJ...788...33K},
	doi = {10.1088/0004-637X/788/1/33},
	abstract = {We present the use of continuous-time autoregressive moving average (CARMA) models as a method for estimating the variability features of a light curve, and in particular its power spectral density (PSD). CARMA models fully account for irregular sampling and measurement errors, making them valuable for quantifying variability, forecasting and interpolating light curves, and variability-based classification. We show that the PSD of a CARMA model can be expressed as a sum of Lorentzian functions, which makes them extremely flexible and able to model a broad range of PSDs. We present the likelihood function for light curves sampled from CARMA processes, placing them on a statistically rigorous foundation, and we present a Bayesian method to infer the probability distribution of the PSD given the measured light curve. Because calculation of the likelihood function scales linearly with the number of data points, CARMA modeling scales to current and future massive time-domain data sets. We conclude by applying our CARMA modeling approach to light curves for an X-ray binary, two active galactic nuclei, a long-period variable star, and an RR Lyrae star in order to illustrate their use, applicability, and interpretation.},
	urldate = {2022-03-03},
	journal = {The Astrophysical Journal},
	author = {Kelly, Brandon C. and Becker, Andrew C. and Sobolewska, Malgosia and Siemiginowska, Aneta and Uttley, Phil},
	month = jun,
	year = {2014},
	note = {ADS Bibcode: 2014ApJ...788...33K},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, methods: statistical},
	pages = {33},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\CDDZKRG9\\Kelly et al. - 2014 - Flexible and Scalable Methods for Quantifying Stoc.pdf:application/pdf},
}

@incollection{brockwell_continuous-time_2001,
	series = {Stochastic {Processes}: {Theory} and {Methods}},
	title = {Continuous-time {ARMA} processes},
	volume = {19},
	url = {https://www.sciencedirect.com/science/article/pii/S0169716101190115},
	abstract = {Continuous-time autoregressive (CAR) processes have been of interest to physicists and engineers for many years (see e.g., Fowler, 1936). Early papers dealing with the properties and statistical analysis of such processes, and of the more general continuous-time autoregressive moving average (CARMA) processes, include those of Doob (1944), Bartlett (1946), Phillips (1959) and Durbin (1961). In the last ten years there has been a resurgence of interest in continuous-time processes partly as a result of the very successful application of stochastic differential equation models to problems in finance, exemplified by the derivation of the Black-Scholes option-pricing formula and its generalizations (Hull and White, 1987). Numerous examples of econometric applications of continuous-time models are contained in the book of Bergstrom (1990). Continuous-time models have also been utilized very successfully for the modelling of irregularly-spaced data (Jones, 1981, Jones, 1985, Jones and Ackerson (1990)). At the same time there has been an increasing realization that non-linear time series models provide much better representations of many empirically observed time series than linear models. The threshold ARMA models of Tong, 1983, Tong, 1990, have been particularly successful in representing a wide variety of data sets, and the ARCH and GARCH models of Engle (1982) and Bollerslev (1986) respectively have had great success in the modelling of financial data. Continuous-time versions of ARCH and GARCH models have been developed by Nelson (1990). In this paper we discuss continuous-time ARMA models, their basic properties, their relationship with discrete-time ARMA models, inference based on observations made at discrete times and non-linear processes which include continuous-time analogues of Tong's threshold ARMA models.},
	language = {en},
	urldate = {2022-11-02},
	booktitle = {Handbook of {Statistics}},
	publisher = {Elsevier},
	author = {Brockwell, P. J.},
	month = jan,
	year = {2001},
	doi = {10.1016/S0169-7161(01)19011-5},
	pages = {249--276},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\EEVI8T26\\Brockwell - 2001 - Continuous-time ARMA processes.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\stoz1\\Zotero\\storage\\AYX7T6MM\\S0169716101190115.html:text/html},
}

@article{yu_eztao_2022,
	title = {{EzTao}: {Easier} {CARMA} {Modeling}},
	shorttitle = {{EzTao}},
	url = {https://ui.adsabs.harvard.edu/abs/2022ascl.soft01001Y},
	abstract = {EzTao models time series as a continuous-time autoregressive moving-average (CARMA) process. EzTao utilizes celerite (ascl:1709.008), a fast and scalable Gaussian Process Regression library, to evaluate the likelihood function. On average, EzTao is ten times faster than other tools relying on a Kalman filter for likelihood computation.},
	urldate = {2022-11-02},
	journal = {Astrophysics Source Code Library},
	author = {Yu, Weixiang and Richards, Gordon T.},
	month = jan,
	year = {2022},
	note = {ADS Bibcode: 2022ascl.soft01001Y},
	keywords = {Software},
	pages = {ascl:2201.001},
}

@misc{foreman-mackey_dfmtinygp_2022,
	title = {dfm/tinygp: v0.2.3},
	shorttitle = {dfm/tinygp},
	url = {https://zenodo.org/record/7269074},
	abstract = {What's Changed Fixing \#87 by @dfm in https://github.com/dfm/tinygp/pull/88 found two typos by @theorashid in https://github.com/dfm/tinygp/pull/92 Updating notebook execution config to remove warnings by @dfm in https://github.com/dfm/tinygp/pull/93 Minor Typos by @yadav-sachin in https://github.com/dfm/tinygp/pull/99 fix typo in docs by @andrewfowlie in https://github.com/dfm/tinygp/pull/107 Update tree\_map -{\textgreater} tree\_util.tree\_map to avoid FutureWarning by @tkillestein in https://github.com/dfm/tinygp/pull/114 Checking tree structure and shapes of X\_test input to condition by @dfm in https://github.com/dfm/tinygp/pull/119 Removing deprecation warning and jitting predict by @dfm in https://github.com/dfm/tinygp/pull/120 Fixing the gradient of the L2 distance at the origin by @dfm in https://github.com/dfm/tinygp/pull/121 Adding check for unsorted input coordinates when using QuasisepSolver by @dfm in https://github.com/dfm/tinygp/pull/123 Fixing behavior of DotProduct kernel on scalar inputs by @dfm in https://github.com/dfm/tinygp/pull/124 Release candidate v0.2.3 by @dfm in https://github.com/dfm/tinygp/pull/125 New Contributors @andrewfowlie made their first contribution in https://github.com/dfm/tinygp/pull/107 @tkillestein made their first contribution in https://github.com/dfm/tinygp/pull/114 Full Changelog: https://github.com/dfm/tinygp/compare/v0.2.2...v0.2.3},
	urldate = {2022-11-02},
	publisher = {Zenodo},
	author = {Foreman-Mackey, Dan and Yadav, Sachin and theorashid and Fowlie, Andrew and Tronsgaard, Ren√© and Schmerler, Steve and Killestein, Thomas},
	month = oct,
	year = {2022},
	doi = {10.5281/zenodo.7269074},
	file = {Zenodo Snapshot:C\:\\Users\\stoz1\\Zotero\\storage\\EBTGCWJG\\7269074.html:text/html},
}

@article{foreman-mackey_fast_2017,
	title = {Fast and scalable {Gaussian} process modeling with applications to astronomical time series},
	volume = {154},
	issn = {1538-3881},
	url = {http://arxiv.org/abs/1703.09710},
	doi = {10.3847/1538-3881/aa9332},
	abstract = {The growing field of large-scale time domain astronomy requires methods for probabilistic data analysis that are computationally tractable, even with large datasets. Gaussian Processes are a popular class of models used for this purpose but, since the computational cost scales, in general, as the cube of the number of data points, their application has been limited to small datasets. In this paper, we present a novel method for Gaussian Process modeling in one-dimension where the computational requirements scale linearly with the size of the dataset. We demonstrate the method by applying it to simulated and real astronomical time series datasets. These demonstrations are examples of probabilistic inference of stellar rotation periods, asteroseismic oscillation spectra, and transiting planet parameters. The method exploits structure in the problem when the covariance function is expressed as a mixture of complex exponentials, without requiring evenly spaced observations or uniform noise. This form of covariance arises naturally when the process is a mixture of stochastically-driven damped harmonic oscillators -- providing a physical motivation for and interpretation of this choice -- but we also demonstrate that it can be a useful effective model in some other cases. We present a mathematical description of the method and compare it to existing scalable Gaussian Process methods. The method is fast and interpretable, with a range of potential applications within astronomical data analysis and beyond. We provide well-tested and documented open-source implementations of this method in C++, Python, and Julia.},
	number = {6},
	urldate = {2022-11-02},
	journal = {AJ},
	author = {Foreman-Mackey, Daniel and Agol, Eric and Ambikasaran, Sivaram and Angus, Ruth},
	month = nov,
	year = {2017},
	note = {arXiv:1703.09710 [astro-ph, physics:physics, stat]},
	keywords = {Astrophysics - Solar and Stellar Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Earth and Planetary Astrophysics, Physics - Data Analysis, Statistics and Probability, Statistics - Applications},
	pages = {220},
	file = {arXiv Fulltext PDF:C\:\\Users\\stoz1\\Zotero\\storage\\86QK6KQG\\Foreman-Mackey et al. - 2017 - Fast and scalable Gaussian process modeling with a.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\stoz1\\Zotero\\storage\\23733BSG\\1703.html:text/html},
}

@article{sun_pyccf_2018,
	title = {{PyCCF}: {Python} {Cross} {Correlation} {Function} for reverberation mapping studies},
	shorttitle = {{PyCCF}},
	url = {https://ui.adsabs.harvard.edu/abs/2018ascl.soft05032S},
	abstract = {PyCCF emulates a Fortran program written by B. Peterson for use with reverberation mapping. The code cross correlates two light curves that are unevenly sampled using linear interpolation and measures the peak and centroid of the cross-correlation function. In addition, it is possible to run Monto Carlo iterations using flux randomization and random subset selection (RSS) to produce cross-correlation centroid distributions to estimate the uncertainties in the cross correlation results.},
	urldate = {2022-11-02},
	journal = {Astrophysics Source Code Library},
	author = {Sun, Mouyuan and Grier, C. J. and Peterson, B. M.},
	month = may,
	year = {2018},
	note = {ADS Bibcode: 2018ascl.soft05032S},
	keywords = {Software},
	pages = {ascl:1805.032},
}

@article{peterson_uncertainties_1998,
	title = {On {Uncertainties} in {Cross}-{Correlation} {Lags} and the {Reality} of {Wavelength}-dependent {Continuum} {Lags} in {Active} {Galactic} {Nuclei}},
	volume = {110},
	issn = {0004-6280},
	url = {https://ui.adsabs.harvard.edu/abs/1998PASP..110..660P},
	doi = {10.1086/316177},
	abstract = {We describe a model-independent method of assessing the uncertainties in cross-correlation lags determined from the light curves of active galactic nuclei (AGNs) and use this method to investigate the reality of lags between UV and optical continuum variations in well-studied AGNs. Our results confirm the existence of such lags in NGC 7469. We find that the continuum variations at 1825, 4845, and 6962 √Ö follow those at 1315 √Ö by 0.22{\textasciicircum}+0.12\_-0.13, 1.25{\textasciicircum}+0.48\_-0.35, and 1.84{\textasciicircum}+0.93\_-0.94 days, respectively, based on the centroids of the cross-correlation functions; the error intervals quoted correspond to 68\% confidence levels, and each of these lags is greater than zero at no less than 97\% confidence. We do not find statistically significant interband continuum lags in NGC 5548, NGC 3783, or Fairall 9. Wavelength-dependent continuum lags may be marginally detected in the case of NGC 4151. However, on the basis of theoretical considerations, wavelength-dependent continuum lags in sources other than NGC 7469 are not expected to have been detectable in previous experiments. We also confirm the existence of a statistically significant lag between X-ray and UV continuum variations in the blazar PKS 2155-304.},
	urldate = {2022-11-02},
	journal = {Publications of the Astronomical Society of the Pacific},
	author = {Peterson, Bradley M. and Wanders, Ignaz and Horne, Keith and Collier, Stefan and Alexander, Tal and Kaspi, Shai and Maoz, Dan},
	month = jun,
	year = {1998},
	note = {ADS Bibcode: 1998PASP..110..660P},
	keywords = {Astrophysics, GALAXIES: SEYFERT, GALAXIES: ACTIVE, METHODS: DATA ANALYSIS},
	pages = {660--670},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\M8GWBV2Y\\Peterson et al. - 1998 - On Uncertainties in Cross-Correlation Lags and the.pdf:application/pdf},
}

@misc{jankov_pyzdcf_2022,
	title = {{pyZDCF}: {Initial} {Release}},
	shorttitle = {{pyZDCF}},
	url = {https://zenodo.org/record/7253034},
	abstract = {pyZDCF¬†is a Python module that emulates a widely used Fortran program called ZDCF (Z-transformed Discrete Correlation Function,¬†Alexander 1997). It is used for robust estimation of cross-correlation function of sparse and unevenly sampled astronomical time-series. This Python implementation also introduces sparse matrices in order to significantly reduce RAM usage when running the code on large time-series ({\textgreater} 3000 points). pyZDCF is based on the original Fortran code fully developed by Prof. Tal Alexander from Weizmann Institute of Science, Israel.},
	urldate = {2022-11-02},
	publisher = {Zenodo},
	author = {Jankov, Isidora and Kovaƒçeviƒá, Andjelka B. and Iliƒá, Dragana and S√°nchez-S√°ez, Paula and Nikutta, Robert},
	month = oct,
	year = {2022},
	doi = {10.5281/zenodo.7253034},
	keywords = {AGN variability, astronomy, astrophysics, time-series},
}

@article{alexander_is_1997,
	title = {Is {AGN} {Variability} {Correlated} with {Other} {AGN} {Properties}? {ZDCF} {Analysis} of {Small} {Samples} of {Sparse} {Light} {Curves}},
	volume = {218},
	shorttitle = {Is {AGN} {Variability} {Correlated} with {Other} {AGN} {Properties}?},
	url = {https://ui.adsabs.harvard.edu/abs/1997ASSL..218..163A},
	doi = {10.1007/978-94-015-8941-3_14},
	abstract = {The origin of AGN variability is still unknown. One approach to this problem is to look for possible correlations between the properties of the variability, such as the typical variability time-scale, and other properties of the AGN, such as luminosity or redshift. This raises the problem of quantifying the variability timescale of AGN light curves, which are often sparse and unevenly sampled. I present here a method that is particularly useful for the exploratory study of such correlations in small samples, and is based on the z-transformed discrete correlation function (ZDCF). The ZDCF is a statistical algorithm for estimating the cross-correlation function of time series. Its relative strength lies in the analysis of sparse, unevenly sampled light curves. This algorithm differs from the discrete correlation function (DCF) of Edelson amp; Krolik, from which it evolved, in that it bins the data points into equal population bins and uses Fisher's z-transform to stabilize the highly skewed distribution of the correlation coefficient. Simulations show that according to various criteria, these modifications improve the ZDCF performance over that of the DCF in the low sampling rate limit. I propose a simple measure for the variability time scale, the zero-crossing time of the ZDCF auto-correlation function. I then proceed to demonstrate the ZDCF's strength when employed together with non-parametric estimators, by using it to uncover a correlation between AGN variability time scale and luminosity properties in a small (30) simulated sample of unevenly sampled and sparse (15 observations) light curves. I show that the ZDCF is 6 times more likely than the DCF to detect the hidden correlation at the 99{\textbackslash}\% confidence level and 3 times more likely to do so at the 90{\textbackslash}\% confidence level.},
	urldate = {2022-11-02},
	author = {Alexander, Tal},
	month = jan,
	year = {1997},
	note = {Conference Name: Astronomical Time Series
ADS Bibcode: 1997ASSL..218..163A},
	pages = {163},
}

@article{white_comments_1994,
	title = {{COMMENTS} {ON} {CROSS}-{CORRELATION} {METHODOLOGY} {IN} {VARIABILITY} {STUDIES} {OF} {ACTIVE} {GALACTIC} {NUCLEI}},
	volume = {106},
	issn = {1538-3873},
	url = {https://iopscience.iop.org/article/10.1086/133456/meta},
	doi = {10.1086/133456},
	language = {en},
	number = {702},
	urldate = {2022-11-02},
	journal = {PASP},
	author = {White, Russell J. and Peterson, Bradley M.},
	month = aug,
	year = {1994},
	note = {Publisher: IOP Publishing},
	pages = {879},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\ZERLLWKP\\White and Peterson - 1994 - COMMENTS ON CROSS-CORRELATION METHODOLOGY IN VARIA.pdf:application/pdf;Snapshot:C\:\\Users\\stoz1\\Zotero\\storage\\XBXVAEML\\133456.html:text/html},
}

@article{grier_sloan_2017,
	title = {The {Sloan} {Digital} {Sky} {Survey} {Reverberation} {Mapping} {Project}: {HŒ±} and {HŒ≤} {Reverberation} {Measurements} from {First}-year {Spectroscopy} and {Photometry}},
	volume = {851},
	issn = {0004-637X},
	shorttitle = {The {Sloan} {Digital} {Sky} {Survey} {Reverberation} {Mapping} {Project}},
	url = {https://dx.doi.org/10.3847/1538-4357/aa98dc},
	doi = {10.3847/1538-4357/aa98dc},
	abstract = {We present reverberation mapping results from the first year of combined spectroscopic and photometric observations of the Sloan Digital Sky Survey Reverberation Mapping Project. We successfully recover reverberation time delays between the g+i band emission and the broad HŒ≤ emission line for a total of 44 quasars, and for the broad HŒ± emission line in 18 quasars. Time delays are computed using the JAVELIN and CREAM software and the traditional interpolated cross-correlation function (ICCF): using well-defined criteria, we report measurements of 32 HŒ≤ and 13 HŒ± lags with JAVELIN, 42 HŒ≤ and 17 HŒ± lags with CREAM, and 16 HŒ≤ and eight HŒ± lags with the ICCF. Lag values are generally consistent among the three methods, though we typically measure smaller uncertainties with JAVELIN and CREAM than with the ICCF, given the more physically motivated light curve interpolation and more robust statistical modeling of the former two methods. The median redshift of our HŒ≤-detected sample of quasars is 0.53, significantly higher than that of the previous reverberation mapping sample. We find that in most objects, the time delay of the HŒ± emission is consistent with or slightly longer than that of HŒ≤. We measure black hole masses using our measured time delays and line widths for these quasars. These black hole mass measurements are mostly consistent with expectations based on the local ‚Äì relationship, and are also consistent with single-epoch black hole mass measurements. This work increases the current sample size of reverberation-mapped active galaxies by about two-thirds and represents the first large sample of reverberation mapping observations beyond the local universe (z {\textless} 0.3).},
	language = {en},
	number = {1},
	urldate = {2022-11-08},
	journal = {ApJ},
	author = {Grier, C. J. and Trump, J. R. and Shen, Yue and Horne, Keith and Kinemuchi, Karen and McGreer, Ian D. and Starkey, D. A. and Brandt, W. N. and Hall, P. B. and Kochanek, C. S. and Chen, Yuguang and Denney, K. D. and Greene, Jenny E. and Ho, L. C. and Homayouni, Y. and Li, Jennifer I.-Hsiu and Pei, Liuyi and Peterson, B. M. and Petitjean, P. and Schneider, D. P. and Sun, Mouyuan and AlSayyad, Yusura and Bizyaev, Dmitry and Brinkmann, Jonathan and Brownstein, Joel R. and Bundy, Kevin and Dawson, K. S. and Eftekharzadeh, Sarah and Fernandez-Trincado, J. G. and Gao, Yang and Hutchinson, Timothy A. and Jia, Siyao and Jiang, Linhua and Oravetz, Daniel and Pan, Kaike and Paris, Isabelle and Ponder, Kara A. and Peters, Christina and Rogerson, Jesse and Simmons, Audrey and Smith, Robyn and Wang, {and} Ran},
	month = dec,
	year = {2017},
	note = {Publisher: The American Astronomical Society},
	pages = {21},
	file = {IOP Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\HYZFDBC6\\Grier et al. - 2017 - The Sloan Digital Sky Survey Reverberation Mapping.pdf:application/pdf},
}

@article{zu_is_2013,
	title = {Is {Quasar} {Optical} {Variability} a {Damped} {Random} {Walk}?},
	volume = {765},
	issn = {0004-637X},
	url = {https://ui.adsabs.harvard.edu/abs/2013ApJ...765..106Z},
	doi = {10.1088/0004-637X/765/2/106},
	abstract = {The damped random walk (DRW) model is increasingly used to model the variability in quasar optical light curves, but it is still uncertain whether the DRW model provides an adequate description of quasar optical variability across all timescales. Using a sample of OGLE quasar light curves, we consider four modifications to the DRW model by introducing additional parameters into the covariance function to search for deviations from the DRW model on both short and long timescales. We find good agreement with the DRW model on timescales that are well sampled by the data (from a month to a few years), possibly with some intrinsic scatter in the additional parameters, but this conclusion depends on the statistical test employed and is sensitive to whether the estimates of the photometric errors are correct to within {\textasciitilde}10\%. On very short timescales (below a few months), we see some evidence of the existence of a cutoff below which the correlation is stronger than the DRW model, echoing the recent finding of Mushotzky et al. using quasar light curves from Kepler. On very long timescales ({\textgreater}a few years), the light curves do not constrain models well, but are consistent with the DRW model.},
	urldate = {2022-11-08},
	journal = {The Astrophysical Journal},
	author = {Zu, Ying and Kochanek, C. S. and Koz≈Çowski, Szymon and Udalski, Andrzej},
	month = mar,
	year = {2013},
	note = {ADS Bibcode: 2013ApJ...765..106Z},
	keywords = {methods: data analysis, Astrophysics - Cosmology and Extragalactic Astrophysics, methods: statistical, galaxies: active, galaxies: statistics, methods: numerical},
	pages = {106},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\57MJQTWY\\Zu et al. - 2013 - Is Quasar Optical Variability a Damped Random Walk.pdf:application/pdf},
}

@article{zu_alternative_2011,
	title = {An {Alternative} {Approach} to {Measuring} {Reverberation} {Lags} in {Active} {Galactic} {Nuclei}},
	volume = {735},
	issn = {0004-637X},
	url = {https://ui.adsabs.harvard.edu/abs/2011ApJ...735...80Z},
	doi = {10.1088/0004-637X/735/2/80},
	abstract = {Motivated by recent progress in the statistical modeling of quasar variability, we develop a new approach to measuring emission-line reverberation lags to estimate the size of broad-line regions (BLRs) in active galactic nuclei. Assuming that all emission-line light curves are scaled, smoothed, and displaced versions of the continuum, this alternative approach fits the light curves directly using a damped random walk model and aligns them to recover the time lag and its statistical confidence limits. We introduce the mathematical formalism of this approach and demonstrate its ability to cope with some of the problems for traditional methods, such as irregular sampling, correlated errors, and seasonal gaps. We redetermine the lags for 87 emission lines in 31 quasars and reassess the BLR size-luminosity relationship using 60 HŒ≤ lags. We confirm the general results from the traditional cross-correlation methods, with a few exceptions. Our method, however, also supports a broad range of extensions. In particular, it can simultaneously fit multiple lines and continuum light curves which improves the lag estimate for the lines and provides estimates of the error correlations between them. Determining these correlations is of particular importance for interpreting emission-line velocity-delay maps. We can also include parameters for luminosity-dependent lags or line responses. We use this to detect the scaling of the BLR size with continuum luminosity in NGC 5548.},
	urldate = {2022-11-08},
	journal = {The Astrophysical Journal},
	author = {Zu, Ying and Kochanek, C. S. and Peterson, Bradley M.},
	month = jul,
	year = {2011},
	note = {ADS Bibcode: 2011ApJ...735...80Z},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Cosmology and Nongalactic Astrophysics, quasars: general, galaxies: active, galaxies: Seyfert, galaxies: nuclei},
	pages = {80},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\4I4C8BM3\\Zu et al. - 2011 - An Alternative Approach to Measuring Reverberation.pdf:application/pdf},
}

@techreport{alexander_improved_2013,
	title = {Improved {AGN} light curve analysis with the z-transformed discrete correlation function},
	url = {https://ui.adsabs.harvard.edu/abs/2013arXiv1302.1508A},
	abstract = {The cross-correlation function (CCF) is commonly employed in the study of AGN, where it is used to probe the structure of the broad line region by line reverberation, to study the continuum emission mechanism by correlating multi-waveband light curves and to seek correlations between the variability and other AGN properties. The z -transformed discrete correlation function (ZDCF) is a new method for estimating the CCF of sparse, unevenly sampled light curves. Unlike the commonly used interpolation method, it does not assume that the light curves are smooth and it does provide errors on its estimates. The ZDCF corrects several biases of the discrete correlation function method of Edelson \& Krolik (1988) by using equal population binning and Fisher's z -transform. These lead to a more robust and powerful method of estimating the CCF of sparse light curves of as few as 12 points. Two examples of light curve analysis with the ZDCF are presented. 1) The ZDCF estimate of the auto-correlation function is used to uncover a correlation between AGN magnitude and variability time scale in a small simulated sample of very sparse and irregularly sampled light curves. 2) A maximum likelihood function for the ZDCF peak location is used to estimate the time-lag between two light curves. Fortran 77 and 95 code implementations of the ZDCF and the maximum likelihood peak location (PLIKE) algorithms are freely available (see http://www.weizmann.ac.il/weizsites/tal/research/software/).},
	urldate = {2022-11-08},
	author = {Alexander, Tal},
	month = feb,
	year = {2013},
	note = {Publication Title: arXiv e-prints
ADS Bibcode: 2013arXiv1302.1508A
Type: article},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\45XJ4JQT\\Alexander - 2013 - Improved AGN light curve analysis with the z-trans.pdf:application/pdf},
}

@article{alexander_zdcf_2014,
	title = {{ZDCF}: {Z}-{Transformed} {Discrete} {Correlation} {Function}},
	shorttitle = {{ZDCF}},
	url = {https://ui.adsabs.harvard.edu/abs/2014ascl.soft04002A},
	abstract = {The cross-correlation function (CCF) is commonly employed in the study of AGN, where it is used to probe the structure of the broad line region by line reverberation, to study the continuum emission mechanism by correlating multi-waveband light curves and to seek correlations between the variability and other AGN properties. The z -transformed discrete correlation function (ZDCF) is a method for estimating the CCF of sparse, unevenly sampled light curves. Unlike the commonly used interpolation method, it does not assume that the light curves are smooth and it does provide errors on its estimates.},
	urldate = {2022-11-08},
	journal = {Astrophysics Source Code Library},
	author = {Alexander, Tal},
	month = apr,
	year = {2014},
	note = {ADS Bibcode: 2014ascl.soft04002A},
	keywords = {Software},
	pages = {ascl:1404.002},
}

@article{foreman-mackey_emcee_2013,
	title = {emcee: {The} {MCMC} {Hammer}},
	volume = {125},
	issn = {0004-6280},
	shorttitle = {emcee},
	url = {https://ui.adsabs.harvard.edu/abs/2013PASP..125..306F},
	doi = {10.1086/670067},
	abstract = {We introduce a stable, well tested Python implementation of the affine-invariant ensemble sampler for Markov chain Monte Carlo (MCMC) proposed by Goodman \& Weare (2010). The code is open source and has already been used in several published projects in the astrophysics literature. The algorithm behind emcee has several advantages over traditional MCMC sampling methods and it has excellent performance as measured by the autocorrelation time (or function calls per independent sample). One major advantage of the algorithm is that it requires hand-tuning of only 1 or 2 parameters compared to ‚àºN2 for a traditional algorithm in an N-dimensional parameter space. In this document, we describe the algorithm and the details of our implementation. Exploiting the parallelism of the ensemble method, emcee permits any user to take advantage of multiple CPU cores without extra effort. The code is available online at http://dan.iel.fm/emcee under the GNU General Public License v2.},
	urldate = {2022-12-01},
	journal = {Publications of the Astronomical Society of the Pacific},
	author = {Foreman-Mackey, Daniel and Hogg, David W. and Lang, Dustin and Goodman, Jonathan},
	month = mar,
	year = {2013},
	note = {ADS Bibcode: 2013PASP..125..306F},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Physics - Computational Physics, Statistics - Computation},
	pages = {306},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\WDSG6MV3\\Foreman-Mackey et al. - 2013 - emcee The MCMC Hammer.pdf:application/pdf},
}

@article{foreman-mackey_fast_2017-1,
	title = {Fast and {Scalable} {Gaussian} {Process} {Modeling} with {Applications} to {Astronomical} {Time} {Series}},
	volume = {154},
	issn = {0004-6256},
	url = {https://ui.adsabs.harvard.edu/abs/2017AJ....154..220F},
	doi = {10.3847/1538-3881/aa9332},
	abstract = {The growing field of large-scale time domain astronomy requires methods for probabilistic data analysis that are computationally tractable, even with large data sets. Gaussian processes (GPs) are a popular class of models used for this purpose, but since the computational cost scales, in general, as the cube of the number of data points, their application has been limited to small data sets. In this paper, we present a novel method for GPs modeling in one dimension where the computational requirements scale linearly with the size of the data set. We demonstrate the method by applying it to simulated and real astronomical time series data sets. These demonstrations are examples of probabilistic inference of stellar rotation periods, asteroseismic oscillation spectra, and transiting planet parameters. The method exploits structure in the problem when the covariance function is expressed as a mixture of complex exponentials, without requiring evenly spaced observations or uniform noise. This form of covariance arises naturally when the process is a mixture of stochastically driven damped harmonic oscillators‚Äîproviding a physical motivation for and interpretation of this choice‚Äîbut we also demonstrate that it can be a useful effective model in some other cases. We present a mathematical description of the method and compare it to existing scalable GP methods. The method is fast and interpretable, with a range of potential applications within astronomical data analysis and beyond. We provide well-tested and documented open-source implementations of this method in C++, Python, and Julia.},
	urldate = {2022-12-01},
	journal = {The Astronomical Journal},
	author = {Foreman-Mackey, Daniel and Agol, Eric and Ambikasaran, Sivaram and Angus, Ruth},
	month = dec,
	year = {2017},
	note = {ADS Bibcode: 2017AJ....154..220F},
	keywords = {asteroseismology, Astrophysics - Earth and Planetary Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Solar and Stellar Astrophysics, methods: data analysis, methods: statistical, Physics - Data Analysis, planetary systems, stars: rotation, Statistics - Applications, Statistics and Probability},
	pages = {220},
	file = {Full Text PDF:C\:\\Users\\stoz1\\Zotero\\storage\\DQIRQWLV\\Foreman-Mackey et al. - 2017 - Fast and Scalable Gaussian Process Modeling with A.pdf:application/pdf},
}
